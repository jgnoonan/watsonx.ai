{
    "cells": [
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "![image](https://github.com/IBM/watson-machine-learning-samples/raw/master/cloud/notebooks/headers/AutoAI-Banner_Experiment-Notebook.png)\n# Experiment Notebook - AutoAI Notebook v1.19.3\n\n\nThis notebook contains the steps and code to demonstrate support of AutoAI experiments in the Watson Machine Learning service. It introduces Python API commands for data retrieval, training experiments, persisting pipelines, testing pipelines, refining pipelines, and scoring the resulting model.\n\n**Note:** Notebook code generated using AutoAI will execute successfully. If code is modified or reordered, there is no guarantee it will successfully execute. For details, see: <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/autoai-notebook.html\">Saving an Auto AI experiment as a notebook</a>\n"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Some familiarity with Python is helpful. This notebook uses Python 3.10 and the `ibm_watson_machine_learning` package.\n\n\n## Notebook goals\n\nThe learning goals of this notebook are:\n-  Defining an AutoAI experiment\n-  Training AutoAI models \n-  Comparing trained models\n-  Deploying the model as a web service\n-  Scoring the model to generate predictions\n\n\n\n## Contents\n\nThis notebook contains the following parts:\n\n**[Setup](#setup)**<br>\n&nbsp;&nbsp;[Package installation](#install)<br>\n&nbsp;&nbsp;[Watson Machine Learning connection](#connection)<br>\n**[Experiment configuration](#configuration)**<br>\n&nbsp;&nbsp;[Experiment metadata](#metadata)<br>\n**[Working with completed AutoAI experiment](#work)**<br>\n&nbsp;&nbsp;[Get fitted AutoAI optimizer](#get)<br>\n&nbsp;&nbsp;[Pipelines comparison](#comparison)<br>\n&nbsp;&nbsp;[Get pipeline as a scikit-learn pipeline model](#get_pipeline)<br>\n&nbsp;&nbsp;[Inspect pipeline](#inspect_pipeline)<br>\n&nbsp;&nbsp;&nbsp;&nbsp;[Visualize pipeline model](#visualize)<br>\n&nbsp;&nbsp;&nbsp;&nbsp;[Preview pipeline model as a Python code](#preview)<br>\n**[Deploy and Score](#scoring)**<br>\n&nbsp;&nbsp;[Working with spaces](#working_spaces)<br>\n**[Running AutoAI experiment with Python API](#run)**<br>\n**[Clean up](#cleanup)**<br>\n**[Next steps](#next_steps)**<br>\n**[Copyrights](#copyrights)**"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<a id=\"setup\"></a>\n# Setup"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<a id=\"install\"></a>\n## Package installation\nBefore you use the sample code in this notebook, install the following packages:\n - ibm-watson-machine-learning,\n - autoai-libs,\n - lale,\n - scikit-learn,\n - xgboost,\n - lightgbm,\n - snapml\n"
        },
        {
            "metadata": {
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "cell_type": "code",
            "source": "!pip install ibm-watson-machine-learning | tail -n 1\n!pip install autoai-libs==1.14.13 | tail -n 1\n!pip install 'lale>=0.7,<0.8' | tail -n 1\n!pip install scikit-learn==1.1.1 | tail -n 1\n!pip install xgboost==1.6.2 | tail -n 1\n!pip install lightgbm==3.3.2 | tail -n 1\n!pip install 'snapml==1.8.12' | tail -n 1",
            "execution_count": 1,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from packaging->ibm-watson-machine-learning) (3.0.9)\nSuccessfully installed autoai-libs-1.14.13\nRequirement already satisfied: sortedcontainers~=2.2 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from portion->jsonsubschema>=0.0.6->lale<0.8,>=0.7) (2.4.0)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from scikit-learn==1.1.1) (1.8.1)\nRequirement already satisfied: scipy in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from xgboost==1.6.2) (1.8.1)\nRequirement already satisfied: joblib>=1.0.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from scikit-learn!=0.22.0->lightgbm==3.3.2) (1.1.1)\nRequirement already satisfied: joblib>=1.0.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from scikit-learn->snapml==1.8.12) (1.1.1)\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<a id=\"configuration\"></a>\n# Experiment configuration"
        },
        {
            "metadata": {
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "cell_type": "markdown",
            "source": "<a id=\"metadata\"></a>\n## Experiment metadata\nThis cell defines the metadata for the experiment, including: training_data_references, training_result_reference, experiment_metadata."
        },
        {
            "metadata": {
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "cell_type": "code",
            "source": "from ibm_watson_machine_learning.helpers import DataConnection\nfrom ibm_watson_machine_learning.helpers import ContainerLocation\n\ntraining_data_references = [\n    DataConnection(\n        data_asset_id='816ef157-c91c-420f-9291-0eb9e0af4685'\n    ),\n]\ntraining_result_reference = DataConnection(\n    location=ContainerLocation(\n        path='auto_ml/6932cc35-fc08-4ba7-a65f-8fc6bd5eacfc/wml_data/686a5bb2-d6cb-478c-b76d-9d3465399fe7/data/automl',\n        model_location='auto_ml/6932cc35-fc08-4ba7-a65f-8fc6bd5eacfc/wml_data/686a5bb2-d6cb-478c-b76d-9d3465399fe7/data/automl/model.zip',\n        training_status='auto_ml/6932cc35-fc08-4ba7-a65f-8fc6bd5eacfc/wml_data/686a5bb2-d6cb-478c-b76d-9d3465399fe7/training-status.json'\n    )\n)",
            "execution_count": 2,
            "outputs": []
        },
        {
            "metadata": {
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "cell_type": "code",
            "source": "experiment_metadata = dict(\n    prediction_type='regression',\n    prediction_column='_crunh',\n    holdout_size=0.1,\n    scoring='neg_root_mean_squared_error',\n    csv_separator=',',\n    random_state=33,\n    max_number_of_estimators=2,\n    training_data_references=training_data_references,\n    training_result_reference=training_result_reference,\n    deployment_url='https://us-south.ml.cloud.ibm.com',\n    project_id='fb1f25ac-c832-47fa-acb2-b08835928f81',\n    drop_duplicates=True,\n    include_batched_ensemble_estimators=[]\n)",
            "execution_count": 3,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<a id=\"connection\"></a>\n## Watson Machine Learning connection\n\nThis cell defines the credentials required to work with the Watson Machine Learning service.\n\n**Action**: Provide the IBM Cloud apikey, For details, see [documentation](https://cloud.ibm.com/docs/account?topic=account-userapikey)."
        },
        {
            "metadata": {
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "cell_type": "code",
            "source": "api_key = 'qncq6qPa7H8BA_FBhTlGupHsf0NYtRpJSD2QVJqTvdVz'",
            "execution_count": 4,
            "outputs": []
        },
        {
            "metadata": {
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "cell_type": "code",
            "source": "wml_credentials = {\n    \"apikey\": api_key,\n    \"url\": experiment_metadata['deployment_url']\n}",
            "execution_count": 5,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<a id=\"work\"></a>\n\n\n# Working with the completed AutoAI experiment\n\nThis cell imports the pipelines generated for the experiment. The best pipeline will be saved as a model."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<a id=\"get\"></a>\n\n\n## Get fitted AutoAI optimizer"
        },
        {
            "metadata": {
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "cell_type": "code",
            "source": "from ibm_watson_machine_learning.experiment import AutoAI\n\npipeline_optimizer = AutoAI(wml_credentials, project_id=experiment_metadata['project_id']).runs.get_optimizer(metadata=experiment_metadata)",
            "execution_count": 6,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Use `get_params()` to retrieve configuration parameters."
        },
        {
            "metadata": {
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "cell_type": "code",
            "source": "pipeline_optimizer.get_params()",
            "execution_count": 7,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 7,
                    "data": {
                        "text/plain": "{'name': 'autoaitest',\n 'desc': 'Test AutoAI',\n 'prediction_type': 'regression',\n 'prediction_column': '_crunh',\n 'prediction_columns': None,\n 'timestamp_column_name': None,\n 'scoring': 'neg_root_mean_squared_error',\n 'holdout_size': 0.1,\n 'max_num_daub_ensembles': 2,\n 't_shirt_size': 'a6c4923b-b8e4-444c-9f43-8a7ec3020110',\n 'train_sample_rows_test_size': None,\n 'include_only_estimators': None,\n 'include_batched_ensemble_estimators': None,\n 'backtest_num': None,\n 'lookback_window': None,\n 'forecast_window': None,\n 'backtest_gap_length': None,\n 'cognito_transform_names': None,\n 'data_join_graph': False,\n 'csv_separator': ',',\n 'excel_sheet': None,\n 'encoding': 'utf-8',\n 'positive_label': None,\n 'drop_duplicates': True,\n 'outliers_columns': None,\n 'text_processing': None,\n 'word2vec_feature_number': None,\n 'daub_give_priority_to_runtime': None,\n 'text_columns_names': None,\n 'sampling_type': None,\n 'sample_size_limit': None,\n 'sample_rows_limit': None,\n 'sample_percentage_limit': None,\n 'number_of_batch_rows': None,\n 'n_parallel_data_connections': None,\n 'test_data_csv_separator': ',',\n 'test_data_excel_sheet': None,\n 'test_data_encoding': 'utf-8',\n 'categorical_imputation_strategy': None,\n 'numerical_imputation_strategy': None,\n 'numerical_imputation_value': None,\n 'imputation_threshold': None,\n 'retrain_on_holdout': None,\n 'feature_columns': None,\n 'pipeline_types': None,\n 'supporting_features_at_forecast': None,\n 'numerical_columns': None,\n 'categorical_columns': None,\n 'confidence_level': None,\n 'incremental_learning': None,\n 'early_stop_enabled': None,\n 'early_stop_window_size': None,\n 'run_id': '686a5bb2-d6cb-478c-b76d-9d3465399fe7'}"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "cell_type": "markdown",
            "source": "<a id=\"comparison\"></a>\n## Pipelines comparison\n\nUse the `summary()` method to list trained pipelines and evaluation metrics information in\nthe form of a Pandas DataFrame. You can use the DataFrame to compare all discovered pipelines and select the one you like for further testing."
        },
        {
            "metadata": {
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "cell_type": "code",
            "source": "summary = pipeline_optimizer.summary()\nbest_pipeline_name = list(summary.index)[0]\nsummary",
            "execution_count": 8,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 8,
                    "data": {
                        "text/plain": "               Enhancements                  Estimator  \\\nPipeline Name                                            \nPipeline_1                   SnapRandomForestRegressor   \nPipeline_6              HPO        ExtraTreesRegressor   \nPipeline_2              HPO  SnapRandomForestRegressor   \nPipeline_3          HPO, FE  SnapRandomForestRegressor   \nPipeline_4     HPO, FE, HPO  SnapRandomForestRegressor   \nPipeline_8     HPO, FE, HPO        ExtraTreesRegressor   \nPipeline_7          HPO, FE        ExtraTreesRegressor   \nPipeline_5                         ExtraTreesRegressor   \n\n               training_root_mean_squared_error_(optimized)  \\\nPipeline Name                                                 \nPipeline_1                                         0.259802   \nPipeline_6                                         0.252764   \nPipeline_2                                         0.254755   \nPipeline_3                                         0.254755   \nPipeline_4                                         0.254435   \nPipeline_8                                         0.247132   \nPipeline_7                                         0.248285   \nPipeline_5                                         0.264446   \n\n               holdout_explained_variance  holdout_median_absolute_error  \\\nPipeline Name                                                              \nPipeline_1                       0.147825                       0.144500   \nPipeline_6                       0.070018                       0.131313   \nPipeline_2                       0.058794                       0.151463   \nPipeline_3                       0.058794                       0.151463   \nPipeline_4                       0.069873                       0.154025   \nPipeline_8                       0.023364                       0.187225   \nPipeline_7                       0.054673                       0.159311   \nPipeline_5                      -0.739149                       0.141500   \n\n               holdout_mean_squared_error  training_explained_variance  \\\nPipeline Name                                                            \nPipeline_1                       0.040317                     0.061168   \nPipeline_6                       0.042303                     0.101423   \nPipeline_2                       0.042584                     0.079982   \nPipeline_3                       0.042584                     0.079982   \nPipeline_4                       0.042764                     0.082581   \nPipeline_8                       0.043386                     0.132531   \nPipeline_7                       0.043721                     0.122587   \nPipeline_5                       0.074630                     0.016459   \n\n               training_r2  training_median_absolute_error  \\\nPipeline Name                                                \nPipeline_1        0.015296                        0.184783   \nPipeline_6        0.069130                        0.158509   \nPipeline_2        0.054917                        0.167985   \nPipeline_3        0.054917                        0.167985   \nPipeline_4        0.057288                        0.168052   \nPipeline_8        0.109429                        0.158790   \nPipeline_7        0.100250                        0.176825   \nPipeline_5       -0.031445                        0.195500   \n\n               training_mean_squared_error  holdout_r2  \\\nPipeline Name                                            \nPipeline_1                        0.067731   -0.164884   \nPipeline_6                        0.063995   -0.222267   \nPipeline_2                        0.064928   -0.230397   \nPipeline_3                        0.064928   -0.230397   \nPipeline_4                        0.064765   -0.235584   \nPipeline_8                        0.061247   -0.253562   \nPipeline_7                        0.061886   -0.263236   \nPipeline_5                        0.071118   -1.156307   \n\n               training_mean_absolute_error  holdout_root_mean_squared_error  \\\nPipeline Name                                                                  \nPipeline_1                         0.208119                         0.200791   \nPipeline_6                         0.206561                         0.205677   \nPipeline_2                         0.207723                         0.206360   \nPipeline_3                         0.207723                         0.206360   \nPipeline_4                         0.207108                         0.206794   \nPipeline_8                         0.202028                         0.208293   \nPipeline_7                         0.202308                         0.209095   \nPipeline_5                         0.221293                         0.273185   \n\n               holdout_mean_absolute_error  \nPipeline Name                               \nPipeline_1                        0.157092  \nPipeline_6                        0.166307  \nPipeline_2                        0.167782  \nPipeline_3                        0.167782  \nPipeline_4                        0.167466  \nPipeline_8                        0.177865  \nPipeline_7                        0.171440  \nPipeline_5                        0.190356  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Enhancements</th>\n      <th>Estimator</th>\n      <th>training_root_mean_squared_error_(optimized)</th>\n      <th>holdout_explained_variance</th>\n      <th>holdout_median_absolute_error</th>\n      <th>holdout_mean_squared_error</th>\n      <th>training_explained_variance</th>\n      <th>training_r2</th>\n      <th>training_median_absolute_error</th>\n      <th>training_mean_squared_error</th>\n      <th>holdout_r2</th>\n      <th>training_mean_absolute_error</th>\n      <th>holdout_root_mean_squared_error</th>\n      <th>holdout_mean_absolute_error</th>\n    </tr>\n    <tr>\n      <th>Pipeline Name</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Pipeline_1</th>\n      <td></td>\n      <td>SnapRandomForestRegressor</td>\n      <td>0.259802</td>\n      <td>0.147825</td>\n      <td>0.144500</td>\n      <td>0.040317</td>\n      <td>0.061168</td>\n      <td>0.015296</td>\n      <td>0.184783</td>\n      <td>0.067731</td>\n      <td>-0.164884</td>\n      <td>0.208119</td>\n      <td>0.200791</td>\n      <td>0.157092</td>\n    </tr>\n    <tr>\n      <th>Pipeline_6</th>\n      <td>HPO</td>\n      <td>ExtraTreesRegressor</td>\n      <td>0.252764</td>\n      <td>0.070018</td>\n      <td>0.131313</td>\n      <td>0.042303</td>\n      <td>0.101423</td>\n      <td>0.069130</td>\n      <td>0.158509</td>\n      <td>0.063995</td>\n      <td>-0.222267</td>\n      <td>0.206561</td>\n      <td>0.205677</td>\n      <td>0.166307</td>\n    </tr>\n    <tr>\n      <th>Pipeline_2</th>\n      <td>HPO</td>\n      <td>SnapRandomForestRegressor</td>\n      <td>0.254755</td>\n      <td>0.058794</td>\n      <td>0.151463</td>\n      <td>0.042584</td>\n      <td>0.079982</td>\n      <td>0.054917</td>\n      <td>0.167985</td>\n      <td>0.064928</td>\n      <td>-0.230397</td>\n      <td>0.207723</td>\n      <td>0.206360</td>\n      <td>0.167782</td>\n    </tr>\n    <tr>\n      <th>Pipeline_3</th>\n      <td>HPO, FE</td>\n      <td>SnapRandomForestRegressor</td>\n      <td>0.254755</td>\n      <td>0.058794</td>\n      <td>0.151463</td>\n      <td>0.042584</td>\n      <td>0.079982</td>\n      <td>0.054917</td>\n      <td>0.167985</td>\n      <td>0.064928</td>\n      <td>-0.230397</td>\n      <td>0.207723</td>\n      <td>0.206360</td>\n      <td>0.167782</td>\n    </tr>\n    <tr>\n      <th>Pipeline_4</th>\n      <td>HPO, FE, HPO</td>\n      <td>SnapRandomForestRegressor</td>\n      <td>0.254435</td>\n      <td>0.069873</td>\n      <td>0.154025</td>\n      <td>0.042764</td>\n      <td>0.082581</td>\n      <td>0.057288</td>\n      <td>0.168052</td>\n      <td>0.064765</td>\n      <td>-0.235584</td>\n      <td>0.207108</td>\n      <td>0.206794</td>\n      <td>0.167466</td>\n    </tr>\n    <tr>\n      <th>Pipeline_8</th>\n      <td>HPO, FE, HPO</td>\n      <td>ExtraTreesRegressor</td>\n      <td>0.247132</td>\n      <td>0.023364</td>\n      <td>0.187225</td>\n      <td>0.043386</td>\n      <td>0.132531</td>\n      <td>0.109429</td>\n      <td>0.158790</td>\n      <td>0.061247</td>\n      <td>-0.253562</td>\n      <td>0.202028</td>\n      <td>0.208293</td>\n      <td>0.177865</td>\n    </tr>\n    <tr>\n      <th>Pipeline_7</th>\n      <td>HPO, FE</td>\n      <td>ExtraTreesRegressor</td>\n      <td>0.248285</td>\n      <td>0.054673</td>\n      <td>0.159311</td>\n      <td>0.043721</td>\n      <td>0.122587</td>\n      <td>0.100250</td>\n      <td>0.176825</td>\n      <td>0.061886</td>\n      <td>-0.263236</td>\n      <td>0.202308</td>\n      <td>0.209095</td>\n      <td>0.171440</td>\n    </tr>\n    <tr>\n      <th>Pipeline_5</th>\n      <td></td>\n      <td>ExtraTreesRegressor</td>\n      <td>0.264446</td>\n      <td>-0.739149</td>\n      <td>0.141500</td>\n      <td>0.074630</td>\n      <td>0.016459</td>\n      <td>-0.031445</td>\n      <td>0.195500</td>\n      <td>0.071118</td>\n      <td>-1.156307</td>\n      <td>0.221293</td>\n      <td>0.273185</td>\n      <td>0.190356</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<a id=\"get_pipeline\"></a>\n### Get pipeline as a scikit-learn pipeline model\n\nAfter you compare the pipelines, download and save a scikit-learn pipeline model object from the\nAutoAI training job.\n\n**Tip:** To get a specific pipeline, pass the pipeline name in:\n```\npipeline_optimizer.get_pipeline(pipeline_name=pipeline_name)\n```"
        },
        {
            "metadata": {
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "cell_type": "code",
            "source": "pipeline_model = pipeline_optimizer.get_pipeline()",
            "execution_count": 9,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Next, check the importance of features for selected pipeline."
        },
        {
            "metadata": {
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "cell_type": "code",
            "source": "pipeline_optimizer.get_pipeline_details()['features_importance']",
            "execution_count": 10,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 10,
                    "data": {
                        "text/plain": "        features_importance\nYear                   1.00\nMonth                  0.71\n_crush                 0.00",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>features_importance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Year</th>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>Month</th>\n      <td>0.71</td>\n    </tr>\n    <tr>\n      <th>_crush</th>\n      <td>0.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "**Tip:** If you want to check all the details of the model evaluation metrics, use:\n```\npipeline_optimizer.get_pipeline_details()\n```"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<a id=\"inspect_pipeline\"></a>\n## Inspect pipeline"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<a id=\"visualize\"></a>\n### Visualize pipeline model\n\nPreview pipeline model stages as a graph. Each node's name links to a detailed description of the stage.\n"
        },
        {
            "metadata": {
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "cell_type": "code",
            "source": "pipeline_model.visualize()",
            "execution_count": 11,
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.50.0 (0)\n -->\n<!-- Title: cluster:(root) Pages: 1 -->\n<svg width=\"1303pt\" height=\"149pt\"\n viewBox=\"0.00 0.00 1303.23 148.54\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 144.54)\">\n<title>cluster:(root)</title>\n<g id=\"a_graph0\"><a xlink:title=\"(root) = ...\">\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-144.54 1299.23,-144.54 1299.23,4 -4,4\"/>\n</a>\n</g>\n<!-- numpy_column_selector_0 -->\n<g id=\"node1\" class=\"node\">\n<title>numpy_column_selector_0</title>\n<g id=\"a_node1\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.numpy_column_selector.html&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer\" xlink:title=\"numpy_column_selector_0 = NumpyColumnSelector(columns=[0, 1])\">\n<ellipse fill=\"white\" stroke=\"black\" cx=\"38.18\" cy=\"-103.77\" rx=\"38.37\" ry=\"28.07\"/>\n<text text-anchor=\"middle\" x=\"38.18\" y=\"-112.97\" font-family=\"Times,serif\" font-size=\"11.00\">Numpy&#45;</text>\n<text text-anchor=\"middle\" x=\"38.18\" y=\"-100.97\" font-family=\"Times,serif\" font-size=\"11.00\">Column&#45;</text>\n<text text-anchor=\"middle\" x=\"38.18\" y=\"-88.97\" font-family=\"Times,serif\" font-size=\"11.00\">Selector</text>\n</a>\n</g>\n</g>\n<!-- compress_strings -->\n<g id=\"node2\" class=\"node\">\n<title>compress_strings</title>\n<g id=\"a_node2\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.compress_strings.html&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer\" xlink:title=\"compress_strings = CompressStrings(compress_type=&#39;hash&#39;, dtypes_list=[&#39;float_int_num&#39;, &#39;float_int_num&#39;], missing_values_reference_list=[&#39;&#39;, &#39;&#45;&#39;, &#39;?&#39;, float(&#39;nan&#39;)], misslist_list=[[], []])\">\n<ellipse fill=\"white\" stroke=\"black\" cx=\"159.74\" cy=\"-103.77\" rx=\"47.25\" ry=\"19.6\"/>\n<text text-anchor=\"middle\" x=\"159.74\" y=\"-106.97\" font-family=\"Times,serif\" font-size=\"11.00\">Compress&#45;</text>\n<text text-anchor=\"middle\" x=\"159.74\" y=\"-94.97\" font-family=\"Times,serif\" font-size=\"11.00\">Strings</text>\n</a>\n</g>\n</g>\n<!-- numpy_column_selector_0&#45;&gt;compress_strings -->\n<g id=\"edge1\" class=\"edge\">\n<title>numpy_column_selector_0&#45;&gt;compress_strings</title>\n<path fill=\"none\" stroke=\"black\" d=\"M76.69,-103.77C84.76,-103.77 93.46,-103.77 102.08,-103.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"102.11,-107.27 112.11,-103.77 102.11,-100.27 102.11,-107.27\"/>\n</g>\n<!-- numpy_replace_missing_values_0 -->\n<g id=\"node3\" class=\"node\">\n<title>numpy_replace_missing_values_0</title>\n<g id=\"a_node3\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.numpy_replace_missing_values.html&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer\" xlink:title=\"numpy_replace_missing_values_0 = NumpyReplaceMissingValues(missing_values=[], filling_values=100001)\">\n<ellipse fill=\"white\" stroke=\"black\" cx=\"282.72\" cy=\"-103.77\" rx=\"39.7\" ry=\"36.54\"/>\n<text text-anchor=\"middle\" x=\"282.72\" y=\"-118.97\" font-family=\"Times,serif\" font-size=\"11.00\">Numpy&#45;</text>\n<text text-anchor=\"middle\" x=\"282.72\" y=\"-106.97\" font-family=\"Times,serif\" font-size=\"11.00\">Replace&#45;</text>\n<text text-anchor=\"middle\" x=\"282.72\" y=\"-94.97\" font-family=\"Times,serif\" font-size=\"11.00\">Missing&#45;</text>\n<text text-anchor=\"middle\" x=\"282.72\" y=\"-82.97\" font-family=\"Times,serif\" font-size=\"11.00\">Values</text>\n</a>\n</g>\n</g>\n<!-- compress_strings&#45;&gt;numpy_replace_missing_values_0 -->\n<g id=\"edge2\" class=\"edge\">\n<title>compress_strings&#45;&gt;numpy_replace_missing_values_0</title>\n<path fill=\"none\" stroke=\"black\" d=\"M207.17,-103.77C215.6,-103.77 224.42,-103.77 232.92,-103.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"233.08,-107.27 243.08,-103.77 233.08,-100.27 233.08,-107.27\"/>\n</g>\n<!-- numpy_replace_unknown_values -->\n<g id=\"node4\" class=\"node\">\n<title>numpy_replace_unknown_values</title>\n<g id=\"a_node4\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.numpy_replace_unknown_values.html&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer\" xlink:title=\"numpy_replace_unknown_values = NumpyReplaceUnknownValues(filling_values=100001, filling_values_list=[100001, 100001], missing_values_reference_list=[&#39;&#39;, &#39;&#45;&#39;, &#39;?&#39;, float(&#39;nan&#39;)])\">\n<ellipse fill=\"white\" stroke=\"black\" cx=\"402.86\" cy=\"-103.77\" rx=\"44.6\" ry=\"36.54\"/>\n<text text-anchor=\"middle\" x=\"402.86\" y=\"-118.97\" font-family=\"Times,serif\" font-size=\"11.00\">Numpy&#45;</text>\n<text text-anchor=\"middle\" x=\"402.86\" y=\"-106.97\" font-family=\"Times,serif\" font-size=\"11.00\">Replace&#45;</text>\n<text text-anchor=\"middle\" x=\"402.86\" y=\"-94.97\" font-family=\"Times,serif\" font-size=\"11.00\">Unknown&#45;</text>\n<text text-anchor=\"middle\" x=\"402.86\" y=\"-82.97\" font-family=\"Times,serif\" font-size=\"11.00\">Values</text>\n</a>\n</g>\n</g>\n<!-- numpy_replace_missing_values_0&#45;&gt;numpy_replace_unknown_values -->\n<g id=\"edge3\" class=\"edge\">\n<title>numpy_replace_missing_values_0&#45;&gt;numpy_replace_unknown_values</title>\n<path fill=\"none\" stroke=\"black\" d=\"M322.4,-103.77C330.63,-103.77 339.45,-103.77 348.12,-103.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"348.18,-107.27 358.18,-103.77 348.18,-100.27 348.18,-107.27\"/>\n</g>\n<!-- boolean2float -->\n<g id=\"node5\" class=\"node\">\n<title>boolean2float</title>\n<g id=\"a_node5\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.boolean2float.html&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer\" xlink:title=\"boolean2float = boolean2float()\">\n<ellipse fill=\"white\" stroke=\"black\" cx=\"530.3\" cy=\"-100.77\" rx=\"46.77\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"530.3\" y=\"-97.97\" font-family=\"Times,serif\" font-size=\"11.00\">boolean2float</text>\n</a>\n</g>\n</g>\n<!-- numpy_replace_unknown_values&#45;&gt;boolean2float -->\n<g id=\"edge4\" class=\"edge\">\n<title>numpy_replace_unknown_values&#45;&gt;boolean2float</title>\n<path fill=\"none\" stroke=\"black\" d=\"M447.73,-102.72C455.87,-102.53 464.47,-102.32 472.92,-102.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"473.19,-105.61 483.11,-101.87 473.03,-98.61 473.19,-105.61\"/>\n</g>\n<!-- cat_imputer -->\n<g id=\"node6\" class=\"node\">\n<title>cat_imputer</title>\n<g id=\"a_node6\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.cat_imputer.html&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer\" xlink:title=\"cat_imputer = CatImputer(missing_values=100001, sklearn_version_family=&#39;1&#39;, strategy=&#39;most_frequent&#39;)\">\n<ellipse fill=\"white\" stroke=\"black\" cx=\"649.24\" cy=\"-98.77\" rx=\"36.12\" ry=\"19.6\"/>\n<text text-anchor=\"middle\" x=\"649.24\" y=\"-101.97\" font-family=\"Times,serif\" font-size=\"11.00\">Cat&#45;</text>\n<text text-anchor=\"middle\" x=\"649.24\" y=\"-89.97\" font-family=\"Times,serif\" font-size=\"11.00\">Imputer</text>\n</a>\n</g>\n</g>\n<!-- boolean2float&#45;&gt;cat_imputer -->\n<g id=\"edge5\" class=\"edge\">\n<title>boolean2float&#45;&gt;cat_imputer</title>\n<path fill=\"none\" stroke=\"black\" d=\"M577.18,-99.98C585.64,-99.84 594.47,-99.69 602.92,-99.54\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"603.04,-103.04 612.98,-99.37 602.92,-96.04 603.04,-103.04\"/>\n</g>\n<!-- cat_encoder -->\n<g id=\"node7\" class=\"node\">\n<title>cat_encoder</title>\n<g id=\"a_node7\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.cat_encoder.html&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer\" xlink:title=\"cat_encoder = CatEncoder(encoding=&#39;ordinal&#39;, categories=&#39;auto&#39;, dtype=np.float64, handle_unknown=&#39;error&#39;, sklearn_version_family=&#39;1&#39;)\">\n<ellipse fill=\"white\" stroke=\"black\" cx=\"765.15\" cy=\"-97.77\" rx=\"37.45\" ry=\"19.6\"/>\n<text text-anchor=\"middle\" x=\"765.15\" y=\"-100.97\" font-family=\"Times,serif\" font-size=\"11.00\">Cat&#45;</text>\n<text text-anchor=\"middle\" x=\"765.15\" y=\"-88.97\" font-family=\"Times,serif\" font-size=\"11.00\">Encoder</text>\n</a>\n</g>\n</g>\n<!-- cat_imputer&#45;&gt;cat_encoder -->\n<g id=\"edge6\" class=\"edge\">\n<title>cat_imputer&#45;&gt;cat_encoder</title>\n<path fill=\"none\" stroke=\"black\" d=\"M685.35,-98.46C695.45,-98.37 706.64,-98.27 717.33,-98.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"717.42,-101.68 727.38,-98.09 717.35,-94.68 717.42,-101.68\"/>\n</g>\n<!-- float32_transform_0 -->\n<g id=\"node8\" class=\"node\">\n<title>float32_transform_0</title>\n<g id=\"a_node8\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.float32_transform.html&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer\" xlink:title=\"float32_transform_0 = float32_transform()\">\n<ellipse fill=\"white\" stroke=\"black\" cx=\"889.54\" cy=\"-94.77\" rx=\"44.6\" ry=\"19.6\"/>\n<text text-anchor=\"middle\" x=\"889.54\" y=\"-97.97\" font-family=\"Times,serif\" font-size=\"11.00\">float32_&#45;</text>\n<text text-anchor=\"middle\" x=\"889.54\" y=\"-85.97\" font-family=\"Times,serif\" font-size=\"11.00\">transform</text>\n</a>\n</g>\n</g>\n<!-- cat_encoder&#45;&gt;float32_transform_0 -->\n<g id=\"edge7\" class=\"edge\">\n<title>cat_encoder&#45;&gt;float32_transform_0</title>\n<path fill=\"none\" stroke=\"black\" d=\"M802.87,-96.87C812.9,-96.62 823.98,-96.35 834.75,-96.09\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"835.03,-99.58 844.94,-95.84 834.86,-92.58 835.03,-99.58\"/>\n</g>\n<!-- concat_features -->\n<g id=\"node15\" class=\"node\">\n<title>concat_features</title>\n<g id=\"a_node15\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.rasl.concat_features.html&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer\" xlink:title=\"concat_features = ConcatFeatures()\">\n<ellipse fill=\"white\" stroke=\"black\" cx=\"1010.39\" cy=\"-68.77\" rx=\"40.11\" ry=\"19.6\"/>\n<text text-anchor=\"middle\" x=\"1010.39\" y=\"-71.97\" font-family=\"Times,serif\" font-size=\"11.00\">Concat&#45;</text>\n<text text-anchor=\"middle\" x=\"1010.39\" y=\"-59.97\" font-family=\"Times,serif\" font-size=\"11.00\">Features</text>\n</a>\n</g>\n</g>\n<!-- float32_transform_0&#45;&gt;concat_features -->\n<g id=\"edge13\" class=\"edge\">\n<title>float32_transform_0&#45;&gt;concat_features</title>\n<path fill=\"none\" stroke=\"black\" d=\"M929.78,-86.18C940.55,-83.83 952.32,-81.25 963.43,-78.82\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"964.37,-82.2 973.4,-76.64 962.88,-75.36 964.37,-82.2\"/>\n</g>\n<!-- numpy_column_selector_1 -->\n<g id=\"node9\" class=\"node\">\n<title>numpy_column_selector_1</title>\n<g id=\"a_node9\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.numpy_column_selector.html&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer\" xlink:title=\"numpy_column_selector_1 = NumpyColumnSelector(columns=[2])\">\n<ellipse fill=\"white\" stroke=\"black\" cx=\"282.72\" cy=\"-31.77\" rx=\"38.37\" ry=\"28.07\"/>\n<text text-anchor=\"middle\" x=\"282.72\" y=\"-40.97\" font-family=\"Times,serif\" font-size=\"11.00\">Numpy&#45;</text>\n<text text-anchor=\"middle\" x=\"282.72\" y=\"-28.97\" font-family=\"Times,serif\" font-size=\"11.00\">Column&#45;</text>\n<text text-anchor=\"middle\" x=\"282.72\" y=\"-16.97\" font-family=\"Times,serif\" font-size=\"11.00\">Selector</text>\n</a>\n</g>\n</g>\n<!-- float_str2_float -->\n<g id=\"node10\" class=\"node\">\n<title>float_str2_float</title>\n<g id=\"a_node10\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.float_str2_float.html&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer\" xlink:title=\"float_str2_float = FloatStr2Float(dtypes_list=[&#39;float_num&#39;], missing_values_reference_list=[])\">\n<ellipse fill=\"white\" stroke=\"black\" cx=\"402.86\" cy=\"-31.77\" rx=\"27.65\" ry=\"28.07\"/>\n<text text-anchor=\"middle\" x=\"402.86\" y=\"-40.97\" font-family=\"Times,serif\" font-size=\"11.00\">Float&#45;</text>\n<text text-anchor=\"middle\" x=\"402.86\" y=\"-28.97\" font-family=\"Times,serif\" font-size=\"11.00\">Str2&#45;</text>\n<text text-anchor=\"middle\" x=\"402.86\" y=\"-16.97\" font-family=\"Times,serif\" font-size=\"11.00\">Float</text>\n</a>\n</g>\n</g>\n<!-- numpy_column_selector_1&#45;&gt;float_str2_float -->\n<g id=\"edge8\" class=\"edge\">\n<title>numpy_column_selector_1&#45;&gt;float_str2_float</title>\n<path fill=\"none\" stroke=\"black\" d=\"M321.1,-31.77C335.11,-31.77 351,-31.77 364.96,-31.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"365.2,-35.27 375.2,-31.77 365.2,-28.27 365.2,-35.27\"/>\n</g>\n<!-- numpy_replace_missing_values_1 -->\n<g id=\"node11\" class=\"node\">\n<title>numpy_replace_missing_values_1</title>\n<g id=\"a_node11\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.numpy_replace_missing_values.html&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer\" xlink:title=\"numpy_replace_missing_values_1 = NumpyReplaceMissingValues(missing_values=[], filling_values=float(&#39;nan&#39;))\">\n<ellipse fill=\"white\" stroke=\"black\" cx=\"530.3\" cy=\"-36.77\" rx=\"39.7\" ry=\"36.54\"/>\n<text text-anchor=\"middle\" x=\"530.3\" y=\"-51.97\" font-family=\"Times,serif\" font-size=\"11.00\">Numpy&#45;</text>\n<text text-anchor=\"middle\" x=\"530.3\" y=\"-39.97\" font-family=\"Times,serif\" font-size=\"11.00\">Replace&#45;</text>\n<text text-anchor=\"middle\" x=\"530.3\" y=\"-27.97\" font-family=\"Times,serif\" font-size=\"11.00\">Missing&#45;</text>\n<text text-anchor=\"middle\" x=\"530.3\" y=\"-15.97\" font-family=\"Times,serif\" font-size=\"11.00\">Values</text>\n</a>\n</g>\n</g>\n<!-- float_str2_float&#45;&gt;numpy_replace_missing_values_1 -->\n<g id=\"edge9\" class=\"edge\">\n<title>float_str2_float&#45;&gt;numpy_replace_missing_values_1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M430.46,-32.83C444.88,-33.4 463.15,-34.13 480.05,-34.81\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"480.22,-38.32 490.35,-35.22 480.5,-31.32 480.22,-38.32\"/>\n</g>\n<!-- num_imputer -->\n<g id=\"node12\" class=\"node\">\n<title>num_imputer</title>\n<g id=\"a_node12\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.num_imputer.html&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer\" xlink:title=\"num_imputer = NumImputer(missing_values=float(&#39;nan&#39;), strategy=&#39;median&#39;)\">\n<ellipse fill=\"white\" stroke=\"black\" cx=\"649.24\" cy=\"-39.77\" rx=\"36.12\" ry=\"19.6\"/>\n<text text-anchor=\"middle\" x=\"649.24\" y=\"-42.97\" font-family=\"Times,serif\" font-size=\"11.00\">Num&#45;</text>\n<text text-anchor=\"middle\" x=\"649.24\" y=\"-30.97\" font-family=\"Times,serif\" font-size=\"11.00\">Imputer</text>\n</a>\n</g>\n</g>\n<!-- numpy_replace_missing_values_1&#45;&gt;num_imputer -->\n<g id=\"edge10\" class=\"edge\">\n<title>numpy_replace_missing_values_1&#45;&gt;num_imputer</title>\n<path fill=\"none\" stroke=\"black\" d=\"M569.91,-37.76C580.4,-38.03 591.85,-38.32 602.69,-38.6\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"602.74,-42.1 612.83,-38.86 602.92,-35.11 602.74,-42.1\"/>\n</g>\n<!-- opt_standard_scaler -->\n<g id=\"node13\" class=\"node\">\n<title>opt_standard_scaler</title>\n<g id=\"a_node13\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.opt_standard_scaler.html&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer\" xlink:title=\"opt_standard_scaler = OptStandardScaler(use_scaler_flag=False)\">\n<ellipse fill=\"white\" stroke=\"black\" cx=\"765.15\" cy=\"-41.77\" rx=\"43.68\" ry=\"28.07\"/>\n<text text-anchor=\"middle\" x=\"765.15\" y=\"-50.97\" font-family=\"Times,serif\" font-size=\"11.00\">Opt&#45;</text>\n<text text-anchor=\"middle\" x=\"765.15\" y=\"-38.97\" font-family=\"Times,serif\" font-size=\"11.00\">Standard&#45;</text>\n<text text-anchor=\"middle\" x=\"765.15\" y=\"-26.97\" font-family=\"Times,serif\" font-size=\"11.00\">Scaler</text>\n</a>\n</g>\n</g>\n<!-- num_imputer&#45;&gt;opt_standard_scaler -->\n<g id=\"edge11\" class=\"edge\">\n<title>num_imputer&#45;&gt;opt_standard_scaler</title>\n<path fill=\"none\" stroke=\"black\" d=\"M685.35,-40.39C693.43,-40.53 702.2,-40.68 710.86,-40.83\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"710.87,-44.33 720.93,-41.01 710.99,-37.34 710.87,-44.33\"/>\n</g>\n<!-- float32_transform_1 -->\n<g id=\"node14\" class=\"node\">\n<title>float32_transform_1</title>\n<g id=\"a_node14\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.float32_transform.html&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer\" xlink:title=\"float32_transform_1 = float32_transform()\">\n<ellipse fill=\"white\" stroke=\"black\" cx=\"889.54\" cy=\"-45.77\" rx=\"44.6\" ry=\"19.6\"/>\n<text text-anchor=\"middle\" x=\"889.54\" y=\"-48.97\" font-family=\"Times,serif\" font-size=\"11.00\">float32_&#45;</text>\n<text text-anchor=\"middle\" x=\"889.54\" y=\"-36.97\" font-family=\"Times,serif\" font-size=\"11.00\">transform</text>\n</a>\n</g>\n</g>\n<!-- opt_standard_scaler&#45;&gt;float32_transform_1 -->\n<g id=\"edge12\" class=\"edge\">\n<title>opt_standard_scaler&#45;&gt;float32_transform_1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M808.95,-43.17C817.19,-43.44 825.91,-43.72 834.44,-44\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"834.61,-47.51 844.72,-44.34 834.84,-40.51 834.61,-47.51\"/>\n</g>\n<!-- float32_transform_1&#45;&gt;concat_features -->\n<g id=\"edge14\" class=\"edge\">\n<title>float32_transform_1&#45;&gt;concat_features</title>\n<path fill=\"none\" stroke=\"black\" d=\"M930.77,-53.56C940.98,-55.53 952.03,-57.67 962.54,-59.7\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"961.91,-63.15 972.39,-61.61 963.24,-56.27 961.91,-63.15\"/>\n</g>\n<!-- numpy_permute_array -->\n<g id=\"node16\" class=\"node\">\n<title>numpy_permute_array</title>\n<g id=\"a_node16\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.numpy_permute_array.html&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer\" xlink:title=\"numpy_permute_array = NumpyPermuteArray(axis=0, permutation_indices=[0, 1, 2])\">\n<ellipse fill=\"white\" stroke=\"black\" cx=\"1127.71\" cy=\"-68.77\" rx=\"41.02\" ry=\"28.07\"/>\n<text text-anchor=\"middle\" x=\"1127.71\" y=\"-77.97\" font-family=\"Times,serif\" font-size=\"11.00\">Numpy&#45;</text>\n<text text-anchor=\"middle\" x=\"1127.71\" y=\"-65.97\" font-family=\"Times,serif\" font-size=\"11.00\">Permute&#45;</text>\n<text text-anchor=\"middle\" x=\"1127.71\" y=\"-53.97\" font-family=\"Times,serif\" font-size=\"11.00\">Array</text>\n</a>\n</g>\n</g>\n<!-- concat_features&#45;&gt;numpy_permute_array -->\n<g id=\"edge15\" class=\"edge\">\n<title>concat_features&#45;&gt;numpy_permute_array</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1050.75,-68.77C1058.92,-68.77 1067.63,-68.77 1076.13,-68.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1076.34,-72.27 1086.34,-68.77 1076.34,-65.27 1076.34,-72.27\"/>\n</g>\n<!-- snap_random_forest_regressor -->\n<g id=\"node17\" class=\"node\">\n<title>snap_random_forest_regressor</title>\n<g id=\"a_node17\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.snapml.snap_random_forest_regressor.html&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer\" xlink:title=\"snap_random_forest_regressor = SnapRandomForestRegressor(compress_trees=True, gpu_ids=np.array([0], dtype=np.uint32), max_depth=10, random_state=33)\">\n<ellipse fill=\"white\" stroke=\"black\" cx=\"1249.97\" cy=\"-68.77\" rx=\"45.01\" ry=\"36.54\"/>\n<text text-anchor=\"middle\" x=\"1249.97\" y=\"-83.97\" font-family=\"Times,serif\" font-size=\"11.00\">Snap&#45;</text>\n<text text-anchor=\"middle\" x=\"1249.97\" y=\"-71.97\" font-family=\"Times,serif\" font-size=\"11.00\">Random&#45;</text>\n<text text-anchor=\"middle\" x=\"1249.97\" y=\"-59.97\" font-family=\"Times,serif\" font-size=\"11.00\">Forest&#45;</text>\n<text text-anchor=\"middle\" x=\"1249.97\" y=\"-47.97\" font-family=\"Times,serif\" font-size=\"11.00\">Regressor</text>\n</a>\n</g>\n</g>\n<!-- numpy_permute_array&#45;&gt;snap_random_forest_regressor -->\n<g id=\"edge16\" class=\"edge\">\n<title>numpy_permute_array&#45;&gt;snap_random_forest_regressor</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1168.75,-68.77C1177,-68.77 1185.82,-68.77 1194.49,-68.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1194.54,-72.27 1204.54,-68.77 1194.54,-65.27 1194.54,-72.27\"/>\n</g>\n</g>\n</svg>\n",
                        "text/plain": "<graphviz.graphs.Digraph at 0x7f9c632b3c70>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<a id=\"preview\"></a>\n### Preview pipeline model as a Python code\nIn the next cell, you can preview the saved pipeline model as a Python code.  \nYou can review the exact steps used to create the model.\n\n**Note:** If you want to get sklearn representation, add the following parameter to the `pretty_print` call: `astype='sklearn'`."
        },
        {
            "metadata": {
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "cell_type": "code",
            "source": "pipeline_model.pretty_print(combinators=False, ipython_display=True)",
            "execution_count": 12,
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "<IPython.core.display.Markdown object>",
                        "text/markdown": "```python\nfrom autoai_libs.transformers.exportable import NumpyColumnSelector\nfrom autoai_libs.transformers.exportable import CompressStrings\nfrom autoai_libs.transformers.exportable import NumpyReplaceMissingValues\nfrom autoai_libs.transformers.exportable import NumpyReplaceUnknownValues\nfrom autoai_libs.transformers.exportable import boolean2float\nfrom autoai_libs.transformers.exportable import CatImputer\nfrom autoai_libs.transformers.exportable import CatEncoder\nimport numpy as np\nfrom autoai_libs.transformers.exportable import float32_transform\nfrom lale.operators import make_pipeline\nfrom autoai_libs.transformers.exportable import FloatStr2Float\nfrom autoai_libs.transformers.exportable import NumImputer\nfrom autoai_libs.transformers.exportable import OptStandardScaler\nfrom lale.operators import make_union\nfrom autoai_libs.transformers.exportable import NumpyPermuteArray\nfrom snapml import SnapRandomForestRegressor\n\nnumpy_column_selector_0 = NumpyColumnSelector(columns=[0, 1])\ncompress_strings = CompressStrings(\n    compress_type=\"hash\",\n    dtypes_list=[\"float_int_num\", \"float_int_num\"],\n    missing_values_reference_list=[\"\", \"-\", \"?\", float(\"nan\")],\n    misslist_list=[[], []],\n)\nnumpy_replace_missing_values_0 = NumpyReplaceMissingValues(\n    missing_values=[], filling_values=100001\n)\nnumpy_replace_unknown_values = NumpyReplaceUnknownValues(\n    filling_values=100001,\n    filling_values_list=[100001, 100001],\n    missing_values_reference_list=[\"\", \"-\", \"?\", float(\"nan\")],\n)\ncat_imputer = CatImputer(\n    missing_values=100001,\n    sklearn_version_family=\"1\",\n    strategy=\"most_frequent\",\n)\ncat_encoder = CatEncoder(\n    encoding=\"ordinal\",\n    categories=\"auto\",\n    dtype=np.float64,\n    handle_unknown=\"error\",\n    sklearn_version_family=\"1\",\n)\npipeline_0 = make_pipeline(\n    numpy_column_selector_0,\n    compress_strings,\n    numpy_replace_missing_values_0,\n    numpy_replace_unknown_values,\n    boolean2float(),\n    cat_imputer,\n    cat_encoder,\n    float32_transform(),\n)\nnumpy_column_selector_1 = NumpyColumnSelector(columns=[2])\nfloat_str2_float = FloatStr2Float(\n    dtypes_list=[\"float_num\"], missing_values_reference_list=[]\n)\nnumpy_replace_missing_values_1 = NumpyReplaceMissingValues(\n    missing_values=[], filling_values=float(\"nan\")\n)\nnum_imputer = NumImputer(missing_values=float(\"nan\"), strategy=\"median\")\nopt_standard_scaler = OptStandardScaler(use_scaler_flag=False)\npipeline_1 = make_pipeline(\n    numpy_column_selector_1,\n    float_str2_float,\n    numpy_replace_missing_values_1,\n    num_imputer,\n    opt_standard_scaler,\n    float32_transform(),\n)\nunion = make_union(pipeline_0, pipeline_1)\nnumpy_permute_array = NumpyPermuteArray(axis=0, permutation_indices=[0, 1, 2])\nsnap_random_forest_regressor = SnapRandomForestRegressor(\n    compress_trees=True,\n    gpu_ids=np.array([0], dtype=np.uint32),\n    max_depth=10,\n    random_state=33,\n)\npipeline = make_pipeline(\n    union, numpy_permute_array, snap_random_forest_regressor\n)\n```"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Calling the `predict` method\nIf you want to get a prediction by using the pipeline model object, call `pipeline_model.predict()`.\n\n**Note:** If you want to work with a pure sklearn model:\n - add the following parameter to the `get_pipeline` call: `astype='sklearn'`,\n - or `scikit_learn_pipeline = pipeline_model.export_to_sklearn_pipeline()`"
        },
        {
            "metadata": {
                "tags": []
            },
            "cell_type": "markdown",
            "source": "<a id=\"scoring\"></a>\n## Deploy and Score\n\nIn this section you will learn how to deploy and score the model as a web service."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<a id=\"working_spaces\"></a>\n### Working with spaces\n\nIn this section you will specify a deployment space to organize assets and then deploy and score the model. If you do not have an existing space, you can use the [Deployment Spaces Dashboard](https://dataplatform.cloud.ibm.com/ml-runtime/spaces?context=cpdaas) to create a new space. Follow these steps:\n\n- Click **New Deployment Space**\n- Create an empty space\n- Select Cloud Object Storage\n- Select Watson Machine Learning instance and press **Create**\n- Copy `space_id` and paste it below\n\n**Tip**: You can also use the API to prepare the space for your work. Learn more [here](https://github.com/IBM/watson-machine-learning-samples/blob/master/cloud/notebooks/python_sdk/instance-management/Space%20management.ipynb).\n\n**Action**: Assign or update space ID below."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Deployment creation"
        },
        {
            "metadata": {
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "cell_type": "code",
            "source": "target_space_id = \"e83d5604-99e0-42ef-a30c-892341be85c2\"\n\nfrom ibm_watson_machine_learning.deployment import WebService\n\nservice = WebService(\n    source_wml_credentials=wml_credentials,\n    target_wml_credentials=wml_credentials,\n    source_project_id=experiment_metadata['project_id'],\n    target_space_id=target_space_id\n)\nservice.create(\n    model=best_pipeline_name,\n    metadata=experiment_metadata,\n    deployment_name='Best_pipeline_webservice'\n)",
            "execution_count": 15,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Preparing an AutoAI Deployment...\n",
                    "name": "stdout"
                },
                {
                    "output_type": "stream",
                    "text": "Deployment creation failed. Error: 400. {\"trace\":\"-ju7a54qrjose\",\"errors\":[{\"code\":\"space_lacks_compute\",\"message\":\"Space: e83d5604-99e0-42ef-a30c-892341be85c2 is not associated with a WML instance which is mandatory for create_deployment operation\"}]}\n",
                    "name": "stderr"
                },
                {
                    "output_type": "stream",
                    "text": "Published model uid: 553de966-140d-4ead-9784-2bccb582cc2b\nDeploying model 553de966-140d-4ead-9784-2bccb582cc2b using V4 client.\n{\"trace\":\"-ju7a54qrjose\",\"errors\":[{\"code\":\"space_lacks_compute\",\"message\":\"Space: e83d5604-99e0-42ef-a30c-892341be85c2 is not associated with a WML instance which is mandatory for create_deployment operation\"}]}\n\n\n--------------------------\nDeployment creation failed\n--------------------------\n\n\n",
                    "name": "stdout"
                },
                {
                    "output_type": "error",
                    "ename": "WMLClientError",
                    "evalue": "Deployment creation failed. Error: 400. {\"trace\":\"-ju7a54qrjose\",\"errors\":[{\"code\":\"space_lacks_compute\",\"message\":\"Space: e83d5604-99e0-42ef-a30c-892341be85c2 is not associated with a WML instance which is mandatory for create_deployment operation\"}]}",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mWMLClientError\u001b[0m                            Traceback (most recent call last)",
                        "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mibm_watson_machine_learning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeployment\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WebService\n\u001b[1;32m      5\u001b[0m service \u001b[38;5;241m=\u001b[39m WebService(\n\u001b[1;32m      6\u001b[0m     source_wml_credentials\u001b[38;5;241m=\u001b[39mwml_credentials,\n\u001b[1;32m      7\u001b[0m     target_wml_credentials\u001b[38;5;241m=\u001b[39mwml_credentials,\n\u001b[1;32m      8\u001b[0m     source_project_id\u001b[38;5;241m=\u001b[39mexperiment_metadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproject_id\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      9\u001b[0m     target_space_id\u001b[38;5;241m=\u001b[39mtarget_space_id\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 11\u001b[0m \u001b[43mservice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbest_pipeline_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeployment_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBest_pipeline_webservice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m/opt/conda/envs/Python-3.10/lib/python3.10/site-packages/ibm_watson_machine_learning/deployment/web_service.py:144\u001b[0m, in \u001b[0;36mWebService.create\u001b[0;34m(self, model, deployment_name, serving_name, metadata, training_data, training_target, experiment_run_id, hardware_spec)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     84\u001b[0m            model: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     85\u001b[0m            deployment_name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m            experiment_run_id: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     91\u001b[0m            hardware_spec: Optional[\u001b[38;5;28mdict\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;124;03m\"\"\"Create deployment from a model.\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m    :param model: AutoAI model name\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03m           )\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mdeployment_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeployment_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mserving_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserving_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mtraining_target\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mexperiment_run_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_run_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mdeployment_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43monline\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mhardware_spec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhardware_spec\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m/opt/conda/envs/Python-3.10/lib/python3.10/site-packages/ibm_watson_machine_learning/deployment/base_deployment.py:400\u001b[0m, in \u001b[0;36mBaseDeployment.create\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m     run_details \u001b[38;5;241m=\u001b[39m optimizer_2\u001b[38;5;241m.\u001b[39m_workspace\u001b[38;5;241m.\u001b[39mwml_client\u001b[38;5;241m.\u001b[39mtraining\u001b[38;5;241m.\u001b[39mget_details(\n\u001b[1;32m    388\u001b[0m         optimizer_2\u001b[38;5;241m.\u001b[39mget_params()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m'\u001b[39m], _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    389\u001b[0m     )\n\u001b[1;32m    391\u001b[0m     artifact_name, model_props \u001b[38;5;241m=\u001b[39m prepare_auto_ai_model_to_publish_notebook_normal_scenario(\n\u001b[1;32m    392\u001b[0m         pipeline_model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    393\u001b[0m         result_connection\u001b[38;5;241m=\u001b[39moptimizer\u001b[38;5;241m.\u001b[39m_result_client[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m         auto_pipelines_parameters\u001b[38;5;241m=\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mget_params()\n\u001b[1;32m    398\u001b[0m     )\n\u001b[0;32m--> 400\u001b[0m     deployment_details \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_deploy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpipeline_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifact_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeployment_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdeployment_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmeta_props\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_props\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserving_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mserving_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresult_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_result_client\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;66;03m# note: WSD / CP4D 3.5 part\u001b[39;00m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    410\u001b[0m     training_result_reference \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining_result_reference\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
                        "File \u001b[0;32m/opt/conda/envs/Python-3.10/lib/python3.10/site-packages/ibm_watson_machine_learning/deployment/base_deployment.py:627\u001b[0m, in \u001b[0;36mBaseDeployment._project_to_space_to_project.<locals>._method\u001b[0;34m(self, *method_args, **method_kwargs)\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target_workspace\u001b[38;5;241m.\u001b[39mwml_client\u001b[38;5;241m.\u001b[39mset\u001b[38;5;241m.\u001b[39mdefault_space(\n\u001b[1;32m    624\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target_workspace\u001b[38;5;241m.\u001b[39mspace_id) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target_workspace\u001b[38;5;241m.\u001b[39mwml_client\u001b[38;5;241m.\u001b[39mICP \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 627\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmethod_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmethod_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target_workspace\u001b[38;5;241m.\u001b[39mWMLS \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target_workspace\u001b[38;5;241m.\u001b[39mproject_id:\n",
                        "File \u001b[0;32m/opt/conda/envs/Python-3.10/lib/python3.10/site-packages/ibm_watson_machine_learning/deployment/web_service.py:314\u001b[0m, in \u001b[0;36mWebService._deploy\u001b[0;34m(self, pipeline_model, deployment_name, meta_props, serving_name, result_client, hardware_spec)\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeployment_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target_workspace\u001b[38;5;241m.\u001b[39mwml_client\u001b[38;5;241m.\u001b[39mdeployments\u001b[38;5;241m.\u001b[39mget_uid(deployment_details)\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m WMLClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m deployment_details\n",
                        "File \u001b[0;32m/opt/conda/envs/Python-3.10/lib/python3.10/site-packages/ibm_watson_machine_learning/deployment/web_service.py:308\u001b[0m, in \u001b[0;36mWebService._deploy\u001b[0;34m(self, pipeline_model, deployment_name, meta_props, serving_name, result_client, hardware_spec)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeploying model \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m using V4 client.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(asset_uid))\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 308\u001b[0m     deployment_details \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_target_workspace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwml_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeployments\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43martifact_uid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masset_uid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmeta_props\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeployment_props\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeployment_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target_workspace\u001b[38;5;241m.\u001b[39mwml_client\u001b[38;5;241m.\u001b[39mdeployments\u001b[38;5;241m.\u001b[39mget_uid(deployment_details)\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m WMLClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
                        "File \u001b[0;32m/opt/conda/envs/Python-3.10/lib/python3.10/site-packages/ibm_watson_machine_learning/deployments.py:250\u001b[0m, in \u001b[0;36mDeployments.create\u001b[0;34m(self, artifact_uid, meta_props, rev_id, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28mprint\u001b[39m(reason)\n\u001b[1;32m    249\u001b[0m print_text_header_h2(error_msg)\n\u001b[0;32m--> 250\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m WMLClientError(error_msg \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Error: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(response\u001b[38;5;241m.\u001b[39mstatus_code) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m reason)\n",
                        "\u001b[0;31mWMLClientError\u001b[0m: Deployment creation failed. Error: 400. {\"trace\":\"-ju7a54qrjose\",\"errors\":[{\"code\":\"space_lacks_compute\",\"message\":\"Space: e83d5604-99e0-42ef-a30c-892341be85c2 is not associated with a WML instance which is mandatory for create_deployment operation\"}]}"
                    ]
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Use the `print` method for the deployment object to show basic information about the service: "
        },
        {
            "metadata": {
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "cell_type": "code",
            "source": "print(service)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "To show all available information about the deployment, use the `.get_params()` method."
        },
        {
            "metadata": {
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "cell_type": "code",
            "source": "service.get_params()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### Scoring of webservice\nYou can make a scoring request by calling `score()` on the deployed pipeline."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "If you want to work with the web service in an external Python application, follow these steps to retrieve the service object:\n\n - Initialize the service by `service = WebService(target_wml_credentials=wml_credentials,target_space_id=experiment_metadata['space_id'])`\n - Get deployment_id: `service.list()`\n - Get webservice object: `service.get('deployment_id')`\n\nAfter that you can call `service.score(score_records_df)` method. The `score()` method accepts `pandas.DataFrame` objects. "
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<a id=\"cleanup\"></a>\n### Deleting deployment\nYou can delete the existing deployment by calling the `service.delete()` command.\nTo list the existing web services, use the `service.list()` method."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<a id=\"run\"></a>\n\n## Running the AutoAI experiment with Python API"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "If you want to run the AutoAI experiment using the Python API, follow these steps. The experiment settings were generated basing on parameters set in the AutoAI UI.\n"
        },
        {
            "metadata": {
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "cell_type": "markdown",
            "source": "```\nfrom ibm_watson_machine_learning.experiment import AutoAI\n\nexperiment = AutoAI(wml_credentials, project_id=experiment_metadata['project_id'])\n```"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "```\nOPTIMIZER_NAME = 'custom_name'\n```"
        },
        {
            "metadata": {
                "pycharm": {
                    "name": "#%% raw\n"
                }
            },
            "cell_type": "markdown",
            "source": "```\nfrom ibm_watson_machine_learning.helpers import DataConnection\nfrom ibm_watson_machine_learning.helpers import ContainerLocation\n\ntraining_data_references = [\n    DataConnection(\n        data_asset_id='816ef157-c91c-420f-9291-0eb9e0af4685'\n    ),\n]\ntraining_result_reference = DataConnection(\n    location=ContainerLocation(\n        path='auto_ml/6932cc35-fc08-4ba7-a65f-8fc6bd5eacfc/wml_data/686a5bb2-d6cb-478c-b76d-9d3465399fe7/data/automl',\n        model_location='auto_ml/6932cc35-fc08-4ba7-a65f-8fc6bd5eacfc/wml_data/686a5bb2-d6cb-478c-b76d-9d3465399fe7/data/automl/model.zip',\n        training_status='auto_ml/6932cc35-fc08-4ba7-a65f-8fc6bd5eacfc/wml_data/686a5bb2-d6cb-478c-b76d-9d3465399fe7/training-status.json'\n    )\n)\n```"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "The new pipeline optimizer will be created and training will be triggered."
        },
        {
            "metadata": {
                "pycharm": {
                    "name": "#%%raw\n"
                }
            },
            "cell_type": "markdown",
            "source": "```\npipeline_optimizer = experiment.optimizer(\n    name=OPTIMIZER_NAME,\n    prediction_type=experiment_metadata['prediction_type'],\n    prediction_column=experiment_metadata['prediction_column'],\n    scoring=experiment_metadata['scoring'],\n    holdout_size=experiment_metadata['holdout_size'],\n    csv_separator=experiment_metadata['csv_separator'],\n    drop_duplicates=experiment_metadata['drop_duplicates'],\n    include_batched_ensemble_estimators=experiment_metadata['include_batched_ensemble_estimators'],\n)\n```"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "```\npipeline_optimizer.fit(\n    training_data_references=training_data_references,\n    training_results_reference=training_result_reference,\n)\n```"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "\n<a id=\"next_steps\"></a>\n# Next steps\nYou successfully completed this notebook!\nYou learned how to use ibm-watson-machine-learning to run and explore AutoAI experiments.\nCheck out the official [AutoAI site](https://www.ibm.com/cloud/watson-studio/autoai) for more samples, tutorials, documentation, how-tos, and blog posts."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<a id=\"copyrights\"></a>\n### Copyrights\n\nLicensed Materials - Copyright \u00a9 2023 IBM. This notebook and its source code are released under the terms of the ILAN License.\nUse, duplication disclosure restricted by GSA ADP Schedule Contract with IBM Corp.\n\n**Note:** The auto-generated notebooks are subject to the International License Agreement for Non-Warranted Programs (or equivalent) and License Information document for Watson Studio Auto-generated Notebook (License Terms), such agreements located in the link below. Specifically, the Source Components and Sample Materials clause included in the License Information document for Watson Studio Auto-generated Notebook applies to the auto-generated notebooks.  \n\nBy downloading, copying, accessing, or otherwise using the materials, you agree to the <a href=\"http://www14.software.ibm.com/cgi-bin/weblap/lap.pl?li_formnum=L-AMCU-BYC7LF\">License Terms</a>  \n\n___"
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.10",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.9",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "pycharm": {
            "stem_cell": {
                "cell_type": "raw",
                "metadata": {
                    "collapsed": false
                },
                "source": [
                    "\n"
                ]
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}